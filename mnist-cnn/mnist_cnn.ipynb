{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal content MSFT for now until GA\n",
    "\n",
    "\n",
    "This sample show how to train E2E a plain vanilla convnet using Vienna python SDK and Facebook's deep learing framework's pytorch.\n",
    "\n",
    "Training is performed on GPU based DSVM, and inference through Azure container instance\n",
    "\n",
    "Feel free to swap training compute as the MNIST dataset is used, you can run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AML SDK version : 0.1.0.1095338\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.project import Project\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.exceptions.azureml_exception import UserErrorException\n",
    "from azureml.core.compute_target import RemoteTarget\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.contrib.widgets import RunDetails\n",
    "import helpers\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"AML SDK version :\",azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify variables accordingly except for **location** until GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"fe375bc2-9f1a-4909-ad0d-9319806d5e97\"\n",
    "resource_group = \"vienna_demo_rg\"\n",
    "workspace_name = \"vnext_workspace\"\n",
    "location = 'eastus2'\n",
    "\n",
    "project_folder = 'c:/sources/vienna_projects/mnist_demo'\n",
    "project_name = \"mnist_cnn\"\n",
    "history_name = project_name + '_history'\n",
    "\n",
    "dockerrun = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace name: vnext_workspace\n",
      "project directory:  c:\\sources\\vienna_projects\\mnist_demo\n",
      "project history:  mnist_cnn_history\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.get_or_create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = location)\n",
    "project = Project.attach(ws, history_name, project_folder)\n",
    "\n",
    "\n",
    "project_folder = project.project_directory\n",
    "print(\"workspace name:\",ws.name)\n",
    "print(\"project directory: \", project.project_directory)\n",
    "print(\"project history: \", project.history.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\sources\\vienna_projects\\mnist_demo/network.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/network.py\n",
    "\n",
    "import os \n",
    "from azureml.core.run import Run\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "##### network definition input->conv->maxpool->conv->maxpool->fc->softmax\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        kernel_shape=(2, 2)\n",
    "        stride=(2, 2)\n",
    "        padding=0\n",
    "        self.fc_neurons = 392\n",
    "        num_labels = 10\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4,\n",
    "                               kernel_size=(3, 3),stride=(1, 1),\n",
    "                               padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_shape,stride, padding)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8,\n",
    "                               kernel_size=(3, 3),stride=(1, 1),\n",
    "                               padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_shape,stride, padding)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_neurons, num_labels)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.pool1(self.conv1(X)))\n",
    "        out = F.relu(self.pool2(self.conv2(out)))\n",
    "        \n",
    "        out = out.view(-1, self.fc_neurons)\n",
    "        y_pred = self.fc1(out)\n",
    "        \n",
    "        return y_pred \n",
    "        \n",
    "    \n",
    "##### end of network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\sources\\vienna_projects\\mnist_demo/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/train.py\n",
    "\n",
    "import os \n",
    "import shutil\n",
    "\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from network import ConvNet\n",
    "\n",
    "\n",
    "class learner():\n",
    "    \n",
    "    def __init__(self, train_data, run):\n",
    "        batch_size = 32\n",
    "        self.num_epochs = 10\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #print(\"training on\", self.device)\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print('Training on {} \\nFound {} CUDA Devices' .format(self.device, num_gpus))\n",
    "        \n",
    "        ''' breaks inference on ACI for now\n",
    "        if num_gpus > 1: \n",
    "            self.model = nn.DataParallel(self.model)'''\n",
    "\n",
    "        self.loader = DataLoader(dataset=train_data, \n",
    "                                  batch_size=batch_size, \n",
    "                                  shuffle=True)\n",
    "        \n",
    "        \n",
    "        self.model = ConvNet().to(self.device)\n",
    "        print(self.model)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)  \n",
    "        self.optimizer = Adam(self.model.parameters(), lr=1e-5)\n",
    "        \n",
    "        self.run = run \n",
    "    \n",
    "    def train(self):\n",
    "        model = self.model.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch_idx, (X, y) in enumerate(self.loader):\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                \n",
    "                y_pred = model(X)\n",
    "                \n",
    "                loss = self.criterion(y_pred, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward() \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                _, argmax = torch.max(y_pred, 1)\n",
    "                accuracy = (y == argmax.squeeze()).float().mean()\n",
    "                \n",
    "                if not batch_idx % 1000:\n",
    "                    \n",
    "                    self.run.log(\"loss\", loss.item())\n",
    "                    self.run.log(\"accuracy\", accuracy.item())\n",
    "                    print ('epoch [{}/{}], loss: {:.4f}, accuracy: {:.2f}' \n",
    "                           .format(epoch+1, self.num_epochs, loss.item(), accuracy.item()))\n",
    "            \n",
    "        return model\n",
    "            \n",
    "\n",
    "    \n",
    "def train_network():\n",
    "    torch.manual_seed(123)\n",
    "    print(\"Pytorch version\", torch.__version__)\n",
    "    \n",
    "    mnist_folder = 'mnist_dataset'\n",
    "    model_path = 'mnist_model.pth'\n",
    "    model_name = 'mnist-model'\n",
    "    \n",
    "    mnist_mean = 0.1307\n",
    "    mnist_std = 0.3081\n",
    "    \n",
    "    do_download = False \n",
    "    \n",
    "    if not os.path.isdir(mnist_folder):\n",
    "        os.mkdir(mnist_folder)\n",
    "        do_download = True\n",
    "        \n",
    "        \n",
    "    train_dataset = datasets.MNIST(root=mnist_folder,train=True, \n",
    "                               transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((mnist_mean,), (mnist_std,))\n",
    "                               ]),download=do_download)\n",
    "    \n",
    "    run =  Run.get_submitted_run()\n",
    "    \n",
    "    network = learner(train_dataset, run)\n",
    "    model = network.train()\n",
    "    \n",
    "    print(\"Model saved to\", model_path)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    run.upload_file(name = \"outputs/\" + model_path,\n",
    "                    path_or_stream = model_path)\n",
    "    model = run.register_model(model_name = model_name,\n",
    "                       model_path = \"outputs/\" + model_path)\n",
    "    print(\"Model registered as :\" ,model.id)\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(test_directory)\n",
    "    except OSError as e:\n",
    "    print (\"Error: %s.\" % (e.strerror))\n",
    "\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Attach DSVM compute to project\n",
    "\n",
    "\n",
    "Modify your Azure DSVM information accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvm_compute = RemoteTarget(name = \"gpu-dsvm\", \n",
    "                            address = \"40.114.199.8:22\", \n",
    "                            username = \"sasuke\", \n",
    "                            password = \"Nchedek2012!\")\n",
    "try:\n",
    "    # Attaches a DSVM as a compute target.\n",
    "    project.attach_legacy_compute_target(dsvm_compute)\n",
    "except UserErrorException as e:\n",
    "    print(\"Caught = {}\".format(e.message))\n",
    "    print(\"Compute config already attached.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Configure run on DSVM\n",
    "\n",
    "\n",
    "If run is executed on DSVM environment, make sure dependecies are installed in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring local run on remote compute...\n"
     ]
    }
   ],
   "source": [
    "run_config = RunConfiguration.load(project_object = project, run_config_name =  \"gpu-dsvm\")\n",
    "\n",
    "if not dockerrun:\n",
    "    \n",
    "    print(\"Configuring local run on remote compute...\")\n",
    "    run_config.environment.python.interpreter_path = '/anaconda/envs/py35/bin/python'\n",
    "    run_config.environment.python.user_managed_dependencies = True\n",
    "else:\n",
    "    \n",
    "    print(\"Configuring docker  run on remote compute...\")\n",
    "    run_config.environment.docker.enabled = True\n",
    "    run_config.environment.docker.base_image = \"pytorch/pytorch:0.4_cuda9_cudnn7\"#azureml.core.runconfig.DEFAULT_GPU_IMAGE\n",
    "    print('Base Docker image is:', run_config.environment.docker.base_image )\n",
    "\n",
    "    # Ask system to provision a new one based on the conda_dependencies.yml file\n",
    "    run_config.environment.python.user_managed_dependencies = False\n",
    "    run_config.prepare_environment = True\n",
    "\n",
    "    # create a new CondaDependencies obj\n",
    "    cd = CondaDependencies()\n",
    "\n",
    "    # add pytorch as a conda dependency\n",
    "    cd.add_channel('pytorch')\n",
    "    cd.add_conda_package('pytorch')\n",
    "    cd.add_conda_package('torchvision')\n",
    "\n",
    "    cd.save_to_file(project_dir = project_folder, file_name='conda_dependencies.yml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml._run_impl.run_base.mnist_cnn_history_1531340674084:Return type is deprecated, the updated return type will mirror get_details\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2838cc3d94f47c2a559e18606f57073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "run = Run.submit(project_object = project,\n",
    "                 run_config = run_config,\n",
    "                 script_to_run = 'train.py')\n",
    "\n",
    "run.wait_for_completion(show_output = False)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Operationalize model\n",
    "\n",
    "This is done in 2 steps:\n",
    "\n",
    "- Images preparation\n",
    "- Deploy image to ACI for serving\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Image preparation\n",
    "\n",
    "We carried this through:\n",
    "\n",
    "- creation of score script\n",
    "- creation of YML file to include required packages for image creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\sources\\vienna_projects\\mnist_demo/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/score.py\n",
    "\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network import ConvNet\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.run import Run\n",
    "\n",
    "\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "\n",
    "def init():\n",
    "    \n",
    "    global model\n",
    "    \n",
    "    model_name = 'mnist-model'\n",
    "    version = 1\n",
    "    model_path = Model.get_model_path(model_name = model_name)\n",
    "    print(\"model loaded from \",model_path)\n",
    "    model = ConvNet()\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "\n",
    "def run(image):\n",
    "    try:\n",
    "        data = json.loads(image)['image']\n",
    "        data = torch.from_numpy(np.array(data)).type(torch.FloatTensor)\n",
    "        data = data.unsqueeze(0)\n",
    "        \n",
    "        result = model(data)\n",
    "        _, y_pred = torch.max(result, dim = 1)\n",
    "        \n",
    "        return json.dumps({\"predicted\": y_pred.numpy().tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\sources\\vienna_projects\\mnist_demo/pytorch-env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/pytorch-env.yml\n",
    "name: pytorch-env\n",
    "channels:\n",
    "  - pytorch\n",
    "  - conda-forge\n",
    "\n",
    "\n",
    "dependencies:\n",
    "  - python=3.5.2\n",
    "  - pytorch==0.4.0\n",
    "  - torchvision\n",
    "  - cuda90 \n",
    "  \n",
    "  - pip:\n",
    "    - --index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E7501C02541B433786111FE8E140CAA1\n",
    "    - --extra-index-url https://pypi.python.org/simple\n",
    "    - azureml-defaults\n",
    "    - scikit-learn>=0.19.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Deploy Webservice to ACI\n",
    "\n",
    "This will take a while...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist-model:12 2018-07-11 19:12:09.536076+00:00 aml://asset/bfa89dd8b3eb41728847cd616981ffa9\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'pytorch-env.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\u001b[0m in \u001b[0;36mdeploy_from_model\u001b[1;34m(workspace, name, models, runtime, execution_script, docker_file, conda_file, dependencies, schema_file, enable_gpu, deployment_config, deployment_target)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m    199\u001b[0m         image = Image.create(workspace, name, models, runtime, execution_script, docker_file, conda_file, dependencies,\n\u001b[1;32m--> 200\u001b[1;33m                              schema_file, enable_gpu)\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreation_state\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'Succeeded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\core\\image.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(workspace, name, models, runtime, execution_script, docker_file, conda_file, dependencies, schema_file, enable_gpu, tags, description)\u001b[0m\n\u001b[0;32m    216\u001b[0m         json_payload = Image._build_create_payload(name, execution_script, runtime, conda_file, docker_file, model_ids,\n\u001b[0;32m    217\u001b[0m                                                    \u001b[0mschema_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                                                    storage_account_name, storage_account_key)\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Creating image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\core\\image.py\u001b[0m in \u001b[0;36m_build_create_payload\u001b[1;34m(name, execution_script, runtime, conda_file, docker_file, model_ids, schema_file, dependencies, enable_gpu, tags, description, storage_account_name, storage_account_key)\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mconda_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconda_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mjson_payload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targetRuntime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'properties'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'condaEnvFile'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mupload_runtime_properties_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconda_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_account_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_account_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdocker_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mdocker_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocker_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\model_management\\_util.py\u001b[0m in \u001b[0;36mupload_runtime_properties_file\u001b[1;34m(file_path, storage_account_name, storage_account_key)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0maz_blob_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     location = upload_dependency_to_azure_blob(file_path, az_container_name, az_blob_name, storage_account_name,\n\u001b[1;32m---> 56\u001b[1;33m                                                storage_account_key)\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\model_management\\_util.py\u001b[0m in \u001b[0;36mupload_dependency_to_azure_blob\u001b[1;34m(file_path, container, asset_id, storage_account_name, storage_account_key, content_type)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mbbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     bbs.create_blob_from_path(container, asset_id, file_path,\n\u001b[1;32m--> 103\u001b[1;33m                               content_settings=ContentSettings(content_type=content_type))\n\u001b[0m\u001b[0;32m    104\u001b[0m     blob_sas = bbs.generate_blob_shared_access_signature(\n\u001b[0;32m    105\u001b[0m         \u001b[0mcontainer_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azure\\storage\\blob\\blockblobservice.py\u001b[0m in \u001b[0;36mcreate_blob_from_path\u001b[1;34m(self, container_name, blob_name, file_path, content_settings, metadata, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0m_validate_not_none\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file_path'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             return self.create_blob_from_stream(\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'pytorch-env.yml'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = ['demo'], \n",
    "                                               description = 'Vienna ACI')\n",
    "\n",
    "models = ws.models('mnist-model')\n",
    "model = max(models, key = lambda model: model.version) if len(models) > 1 else models[0]\n",
    "print(model.id, model.created_time, model.url)       \n",
    "\n",
    "#prod end point torched\n",
    "aci_service_name = 'torched3'\n",
    "aci_service = Webservice.deploy_from_model(deployment_config = aci_config,\n",
    "                                           models = [model],\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws,\n",
    "                                           execution_script = 'score.py',\n",
    "                                           conda_file = \"pytorch-env.yml\",\n",
    "                                           dependencies=['network.py'],\n",
    "                                           runtime =\"python\")\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test dataset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_directory = \"test_images\"\n",
    "\n",
    "do_download = False\n",
    "print(os.path.isdir(test_directory))\n",
    "if not os.path.isdir(test_directory):\n",
    "    os.mkdir(test_directory)\n",
    "    do_download = True\n",
    "    \n",
    "\n",
    "mnist_mean = 0.1307\n",
    "mnist_std = 0.3081\n",
    "mnist_test = datasets.MNIST(root=test_directory,train=False, \n",
    "                               transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((mnist_mean,), (mnist_std,))]),\n",
    "                               download=do_download)\n",
    "\n",
    "num_indices = 24\n",
    "indices = np.random.randint(0,mnist_test.test_data.shape[0],num_indices)\n",
    "images_loader = DataLoader(mnist_test,batch_size=num_indices,\n",
    "                          sampler=SubsetRandomSampler(indices))\n",
    "\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0))) # channel last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aci_service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aci_service' is not defined"
     ]
    }
   ],
   "source": [
    "# FOR NOW: getting new reference to ACI due to transient timeout despite successfull deployment\n",
    "if aci_service is None:\n",
    "    aci_service = AciWebservice(name=aci_service_name,workspace=ws)\n",
    "    \n",
    "print('End point {} is {}, serving on {}' \n",
    "        .format(aci_service.name, aci_service.state, aci_service.scoring_uri))\n",
    "      \n",
    "\n",
    "predictions = []\n",
    "images_iter = iter(images_loader)\n",
    "images,_ = images_iter.next()\n",
    "\n",
    "for test_img in images:\n",
    "    np_img = test_img.numpy()\n",
    "    test_input = json.dumps({'image':np_img.tolist()})\n",
    "    output = json.loads(aci_service.run(test_input))\n",
    "    predictions.append(output['predicted'])\n",
    "    \n",
    "    \n",
    "print(\"predicted\", predictions)\n",
    "imshow(utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aci_service' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c072c8324990>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0maci_service\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0maci_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aci_service' is not defined"
     ]
    }
   ],
   "source": [
    "if aci_service:\n",
    "    aci_service.delete()\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(test_directory)\n",
    "except OSError as e:\n",
    "    print (\"Error: %s.\" % (e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: This method will be deprecated in a week. Please use Run.clean_all method.\n"
     ]
    },
    {
     "ename": "ExperimentExecutionException",
     "evalue": "{\n    \"status_code\": 500,\n    \"text\": {\n        \"correlation\": {\n            \"operation\": \"5a623712-45d0adced001023a\",\n            \"request\": \"gdb7dEYp+zw=\"\n        },\n        \"error\": {\n            \"code\": \"ServiceError\",\n            \"debugInfo\": {\n                \"data\": {},\n                \"errorResponse\": null,\n                \"innerException\": null,\n                \"message\": \"Object reference not set to an instance of an object.\",\n                \"stackTrace\": \"   at Microsoft.MachineLearning.Execution.Services.StrategyState.get_ComputeTargetType() in /opt/vsts/work/1/s/src/azureml-api/src/Execution/Services/StrategyState.cs:line 137\\n   at Microsoft.MachineLearning.Execution.Services.ExecutionStrategyFactory.Create(StrategyState state) in /opt/vsts/work/1/s/src/azureml-api/src/Execution/Services/ExecutionStrategy.cs:line 80\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.Clean(Guid subscriptionId, String resourceGroupName, String workspaceName, String projectName, Boolean all, RunDetails runDetails, String accountName) in /opt/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 325\\n   at lambda_method(Closure , Object )\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\n                \"type\": \"System.NullReferenceException\"\n            },\n            \"details\": [],\n            \"innerError\": null,\n            \"message\": \"InternalServerError\",\n            \"target\": null\n        }\n    },\n    \"url\": \"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/fe375bc2-9f1a-4909-ad0d-9319806d5e97/resourceGroups/vienna_demo_rg/providers/Microsoft.MachineLearningServices/workspaces/vnext_workspace/projects/mnist-demo/clean?all=True\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3fe8166e4dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattach_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist-demo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\core\\project.py\u001b[0m in \u001b[0;36mclean_target\u001b[1;34m(self, run_config)\u001b[0m\n\u001b[0;32m    205\u001b[0m                      \"Run.clean_all method.\")\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mRun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36mclean_all\u001b[1;34m(project_object, run_config)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_commands\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mrun_config_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_run_config_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_commands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_config_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\execution\\_commands.py\u001b[0m in \u001b[0;36mclean\u001b[1;34m(project_object, run_config_object, run_id, all)\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_session_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m         \u001b[0m_raise_request_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Deleting vienna run(s).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[0mclean_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\amlworkbench\\Python\\envs\\vienna\\lib\\site-packages\\azureml\\execution\\_commands.py\u001b[0m in \u001b[0;36m_raise_request_error\u001b[1;34m(response, action)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_sdk_common\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_http_exception_response_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# response.text is a JSON from execution service.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_http_exception_response_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExperimentExecutionException\u001b[0m: {\n    \"status_code\": 500,\n    \"text\": {\n        \"correlation\": {\n            \"operation\": \"5a623712-45d0adced001023a\",\n            \"request\": \"gdb7dEYp+zw=\"\n        },\n        \"error\": {\n            \"code\": \"ServiceError\",\n            \"debugInfo\": {\n                \"data\": {},\n                \"errorResponse\": null,\n                \"innerException\": null,\n                \"message\": \"Object reference not set to an instance of an object.\",\n                \"stackTrace\": \"   at Microsoft.MachineLearning.Execution.Services.StrategyState.get_ComputeTargetType() in /opt/vsts/work/1/s/src/azureml-api/src/Execution/Services/StrategyState.cs:line 137\\n   at Microsoft.MachineLearning.Execution.Services.ExecutionStrategyFactory.Create(StrategyState state) in /opt/vsts/work/1/s/src/azureml-api/src/Execution/Services/ExecutionStrategy.cs:line 80\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.Clean(Guid subscriptionId, String resourceGroupName, String workspaceName, String projectName, Boolean all, RunDetails runDetails, String accountName) in /opt/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 325\\n   at lambda_method(Closure , Object )\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\n                \"type\": \"System.NullReferenceException\"\n            },\n            \"details\": [],\n            \"innerError\": null,\n            \"message\": \"InternalServerError\",\n            \"target\": null\n        }\n    },\n    \"url\": \"https://eastus2.experiments.azureml.net/execution/v1.0/subscriptions/fe375bc2-9f1a-4909-ad0d-9319806d5e97/resourceGroups/vienna_demo_rg/providers/Microsoft.MachineLearningServices/workspaces/vnext_workspace/projects/mnist-demo/clean?all=True\"\n}"
     ]
    }
   ],
   "source": [
    "proj = ws.attach_project('mnist-demo')\n",
    "proj.clean_target(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vienna]",
   "language": "python",
   "name": "conda-env-vienna-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
