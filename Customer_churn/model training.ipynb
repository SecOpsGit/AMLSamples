{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK verison 1.0.17\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "from azureml.core import  (Workspace,Run,VERSION,\n",
    "                           Experiment,Datastore)\n",
    "\n",
    "from azureml.core.runconfig import (RunConfiguration,\n",
    "                                    DEFAULT_GPU_IMAGE)\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core.compute import (AmlCompute, ComputeTarget)\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "from azureml.pipeline.core import (Pipeline, \n",
    "                                   PipelineData)\n",
    "from azureml.pipeline.steps import HyperDriveStep\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.pipeline.steps import HyperDriveStep\n",
    "\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "print('SDK verison', VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSCRIPTION_ID = 'fe375bc2-9f1a-4909-ad0d-9319806d5e97'\n",
    "RESOURCE_GROUP = 'amlenv_rg'\n",
    "WORKSPACE_NAME = 'vienna'\n",
    "\n",
    "PROJECT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = \"customer_churn\"\n",
    "CLUSTER_NAME = \"gpu-cluster\"\n",
    "DATA_DIR = os.path.join(PROJECT_DIR,'data')\n",
    "SCRIPT_DIR = os.path.join(PROJECT_DIR,'train')\n",
    "\n",
    "SOURCE_URL ='https://amlgitsamples.blob.core.windows.net/churn'\n",
    "FILE_NAME = 'CATelcoCustomerChurnTrainingSample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /extdrive1/home/sasuke/dev/amlsamples/Customer_churn/aml_config/config.json\n",
      "Workspace loaded: vienna\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace(workspace_name = WORKSPACE_NAME,\n",
    "               subscription_id = SUBSCRIPTION_ID ,\n",
    "               resource_group = RESOURCE_GROUP)\n",
    "\n",
    "ws.write_config()\n",
    "\n",
    "print('Workspace loaded:', ws.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/extdrive1/home/sasuke/dev/amlsamples/Customer_churn/data/CATelcoCustomerChurnTrainingSample.csv',\n",
       " <http.client.HTTPMessage at 0x7f7bf3c898d0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve(os.path.join(SOURCE_URL,FILE_NAME), \n",
    "                           filename = os.path.join(DATA_DIR,FILE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading /extdrive1/home/sasuke/dev/amlsamples/Customer_churn/data/CATelcoCustomerChurnTrainingSample.csv\n",
      "Uploaded /extdrive1/home/sasuke/dev/amlsamples/Customer_churn/data/CATelcoCustomerChurnTrainingSample.csv, 1 files out of an estimated total of 1\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "data_dir = ds.upload(src_dir=DATA_DIR, target_path='churn', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu-cluster found\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    cluster = ComputeTarget(ws, cluster_name)\n",
    "    print(cluster_name, \"found\")\n",
    "    \n",
    "except ComputeTargetException:\n",
    "    print(cluster_name, \"not found, provisioning....\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',max_nodes=1)\n",
    "\n",
    "    \n",
    "    cluster = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cd = CondaDependencies()\\ncd.add_conda_package(\\'pandas\\')\\ncd.add_conda_package(\\'matplotlib\\')\\ncd.add_conda_package(\\'numpy\\')\\ncd.add_conda_package(\\'scikit-learn\\')\\n#cd.add_channel(channel = \\'gpytorch\\')\\ncd.add_pip_package(\\'gpytorch\\')\\n\\nrun_config = RunConfiguration(framework=\"python\",\\n                              conda_dependencies= cd)\\nrun_config.target = cluster\\nrun_config.environment.docker.enabled = True\\nrun_config.environment.docker.base_image = DEFAULT_GPU_IMAGE\\nrun_config.environment.python.user_managed_dependencies = False'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cd = CondaDependencies()\n",
    "cd.add_conda_package('pandas')\n",
    "cd.add_conda_package('matplotlib')\n",
    "cd.add_conda_package('numpy')\n",
    "cd.add_conda_package('scikit-learn')\n",
    "#cd.add_channel(channel = 'gpytorch')\n",
    "cd.add_pip_package('gpytorch')\n",
    "\n",
    "run_config = RunConfiguration(framework=\"python\",\n",
    "                              conda_dependencies= cd)\n",
    "run_config.target = cluster\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "run_config.environment.python.user_managed_dependencies = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = PipelineData(name = 'processed_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(source_directory=SCRIPT_DIR,\n",
    "                    conda_packages = ['pandas', 'numpy', 'scikit-learn'],\n",
    "                    pip_packages = ['torch>=1.0.0','torchvision','gpytorch'],\n",
    "                    compute_target=cluster,\n",
    "                    entry_script='svdkl_entry.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(512, 1024),\n",
    "        '--epochs': choice(200),\n",
    "        '--neural-net-lr': loguniform(-6, -1),\n",
    "        '--likelihood-lr': loguniform(-6, -1),\n",
    "        '--grid-size': choice(32,64),\n",
    "        '--grid_bounds': choice((-1,1),(0,1)),\n",
    "        '--latent-dim': choice(2),\n",
    "        '--num-mixtures': choice(2,4,6)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=10, slack_factor=0.1)\n",
    "\n",
    "hd_config = HyperDriveRunConfig(estimator=estimator, \n",
    "                                hyperparameter_sampling=ps,\n",
    "                                policy=early_termination_policy,\n",
    "                                primary_metric_name='auc', \n",
    "                                primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                                max_total_runs=2,\n",
    "                                max_concurrent_runs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data_ref = DataReference(data_reference_name=\"data_input\",\n",
    "                         path_on_datastore='churn',\n",
    "                         datastore=ds,\n",
    "                         )'''\n",
    "\n",
    "pre_processing = PythonScriptStep(\n",
    "                            name = 'preprocess dataset',\n",
    "                            script_name = 'preprocess.py',\n",
    "                            arguments = ['--input_path', data_dir,\\\n",
    "                                         '--output_path', processed_dir],\n",
    "                            inputs = [data_dir],\n",
    "                            outputs = [processed_dir],\n",
    "                            compute_target = cluster_name,\n",
    "                            runconfig = run_config\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_step = HyperDriveStep(\n",
    "    name=\"hyper parameters tunning\",\n",
    "    hyperdrive_run_config=hd_config,\n",
    "    estimator_entry_script_arguments=['--data-folder', processed_dir],\n",
    "    inputs=[processed_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step hyper parameters tunning [6c1d0ae3][c532b622-6013-4e03-9291-d452d662d090], (This step is eligible to reuse a previous run's output)\n",
      "Created step preprocess dataset [f0c4717d][7539777d-9318-4292-9f63-22e7400258f8], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference dc399d7cf508496da3b26bde410714c0 for StepId [fa532da6][e6b78b04-c3a5-4837-9e41-08e9196e7813], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 05d9e46c-8f9e-4714-9e09-f31fd42c26fa\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[hd_step])\n",
    "pipeline_run = Experiment(ws, 'Customer_churn').submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e705ae6aa3fa480983627f1951964e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a39a9603ba4f0ca3f65005c9e65509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amlenv]",
   "language": "python",
   "name": "conda-env-amlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
