{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2: Model Building & Evaluation\n",
    "Using the training and test data sets we constructed in the `Code/1_data_ingestion_and_preparation.ipynb` Jupyter notebook, this notebook builds a LSTM network for scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict failure in aircraft engines. We will store the model for deployment in an Azure web service which we build in the `Code/3_operationalization.ipynb` Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK verison 1.0.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core import  (Workspace,Run,VERSION,\n",
    "                           Experiment,Datastore)\n",
    "from azureml.core.compute import (AmlCompute, ComputeTarget)\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "from utils import tensorize\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "print('SDK verison', VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = 'fe375bc2-9f1a-4909-ad0d-9319806d5e97'\n",
    "resource_group = 'amlenv_rg'\n",
    "workspace_name = 'vienna'\n",
    "location = 'westeurope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /home/sasuke/dev/amlsamples/deep_predictive_maintenance/aml_config/config.json\n",
      "Workspace loaded: vienna\n"
     ]
    }
   ],
   "source": [
    "project_folder = os.getcwd()\n",
    "exp_name = \"deep_pred\"\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "ws.write_config()\n",
    "print('Workspace loaded:', ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature data set\n",
    "\n",
    "We have previously created the labeled data set in the `Code\\1_Data Ingestion and Preparation.ipynb` Jupyter notebook and stored it in default datastore of the AML workspace.\n",
    "\n",
    "Here We download the training/testing datasets here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client-Request-ID=7600cf42-fd62-11e8-8ec1-b1aefe35ea0d Retry policy did not allow for a retry: Server-Timestamp=Tue, 11 Dec 2018 16:33:16 GMT, Server-Request-ID=f55fe30d-a01e-0019-5c6f-912594000000, HTTP status code=416, Exception=The range specified is invalid for the current size of the resource. ErrorCode: InvalidRange<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>InvalidRange</Code><Message>The range specified is invalid for the current size of the resource.RequestId:f55fe30d-a01e-0019-5c6f-912594000000Time:2018-12-11T16:33:16.3292181Z</Message></Error>.\n",
      "Client-Request-ID=760177f8-fd62-11e8-8ec1-b1aefe35ea0d Retry policy did not allow for a retry: Server-Timestamp=Tue, 11 Dec 2018 16:33:15 GMT, Server-Request-ID=86ad80b9-d01e-002c-136f-914980000000, HTTP status code=416, Exception=The range specified is invalid for the current size of the resource. ErrorCode: InvalidRange<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>InvalidRange</Code><Message>The range specified is invalid for the current size of the resource.RequestId:86ad80b9-d01e-002c-136f-914980000000Time:2018-12-11T16:33:16.3609718Z</Message></Error>.\n",
      "Client-Request-ID=7600fdc8-fd62-11e8-8ec1-b1aefe35ea0d Retry policy did not allow for a retry: Server-Timestamp=Tue, 11 Dec 2018 16:33:15 GMT, Server-Request-ID=6e15b7de-701e-000a-6e6f-910198000000, HTTP status code=416, Exception=The range specified is invalid for the current size of the resource. ErrorCode: InvalidRange<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>InvalidRange</Code><Message>The range specified is invalid for the current size of the resource.RequestId:6e15b7de-701e-000a-6e6f-910198000000Time:2018-12-11T16:33:16.3607219Z</Message></Error>.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = Datastore.get(ws,'workspaceblobstore')\n",
    "ds.download(project_folder, overwrite=True, show_progress = True)\n",
    "\n",
    "data_path = \"data\"\n",
    "ds_path = ds.path(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and dump a short summary of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  cycle  setting1  setting2  setting3   s1        s2        s3  \\\n",
       "0          1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802   \n",
       "1          1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019   \n",
       "2          1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523   \n",
       "3          1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159   \n",
       "4          1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467   \n",
       "\n",
       "         s4   s5     ...      s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.309757  0.0     ...      0.0  0.333333  0.0  0.0  0.713178  0.724662   \n",
       "1  0.352633  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.731014   \n",
       "2  0.370527  0.0     ...      0.0  0.166667  0.0  0.0  0.627907  0.621375   \n",
       "3  0.331195  0.0     ...      0.0  0.333333  0.0  0.0  0.573643  0.662386   \n",
       "4  0.404625  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.704502   \n",
       "\n",
       "   RUL  label1  label2  cycle_norm  \n",
       "0  191       0       0     0.00000  \n",
       "1  190       0       0     0.00277  \n",
       "2  189       0       0     0.00554  \n",
       "3  188       0       0     0.00831  \n",
       "4  187       0       0     0.01108  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(project_folder, 'preprocessed_train_file.csv'))\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  cycle  setting1  setting2  setting3   s1        s2        s3  \\\n",
       "0          1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661   \n",
       "1          1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551   \n",
       "2          1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632   \n",
       "3          1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154   \n",
       "4          1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082   \n",
       "\n",
       "         s4   s5   ...    s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.269413  0.0   ...    0.0  0.333333  0.0  0.0  0.558140  0.661834   \n",
       "1  0.222316  0.0   ...    0.0  0.416667  0.0  0.0  0.682171  0.686827   \n",
       "2  0.322248  0.0   ...    0.0  0.416667  0.0  0.0  0.728682  0.721348   \n",
       "3  0.408001  0.0   ...    0.0  0.250000  0.0  0.0  0.666667  0.662110   \n",
       "4  0.332039  0.0   ...    0.0  0.166667  0.0  0.0  0.658915  0.716377   \n",
       "\n",
       "   cycle_norm  RUL  label1  label2  \n",
       "0     0.00000  142       0       0  \n",
       "1     0.00277  141       0       0  \n",
       "2     0.00554  140       0       0  \n",
       "3     0.00831  139       0       0  \n",
       "4     0.01108  138       0       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(project_folder, 'preprocessed_test_file.csv'))\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "The traditional predictive maintenance machine learning models are based on feature engineering, the manual construction of variable using domain expertise and intuition. This usually makes these models hard to reuse as the feature are specific to the problem scenario and the available data may vary between customers. Perhaps the most attractive advantage of deep learning they automatically do feature engineering from the data, eliminating the need for the manual feature engineering step.\n",
    "\n",
    "When using LSTMs in the time-series domain, one important parameter is the sequence length, the window to examine for failure signal. This may be viewed as picking a `window_size` (i.e. 5 cycles) for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3). The rolling features included rolling mean and rolling standard deviation over the 5 cycles for each of the 21 sensor values. In deep learning, we allow the LSTMs to extract abstract features out of the sequence of sensor values within the window. The expectation is that patterns within these sensor values will be automatically encoded by the LSTM.\n",
    "\n",
    "Another critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. Computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing over such a long period. LSTMs are able to use larger window sizes and use all the information in the window as input. \n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/ contains more information on the details of LSTM networks.\n",
    "\n",
    "This notebook illustrates the LSTM approach to binary classification using a sequence_length of 50 cycles to predict the probability of engine failure within 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [Keras LSTM](https://keras.io/layers/recurrent/) with [Tensorflow](https://tensorflow.org) as a backend. Here layers expect an input in the shape of an array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step.\n",
    "\n",
    "We define a function to generate this array, as we'll use it repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequence_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af7051515670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequence_length' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, y_train = tensorize(train_df, timestep = sequence_length, istest = False)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "training_dir = './train'\n",
    "os.makedirs(training_dir, exist_ok=True)\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=2)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network\n",
    "\n",
    "Building a Neural Net requires determining the network architecture. In this scenario we will build a network of only 2 layers, with dropout. The first LSTM layer with 100 units, one for each input sequence, followed by another LSTM layer with 50 units. We will also apply dropout each LSTM layer to control overfitting. The final dense output layer employs a sigmoid activation corresponding to the binary classification requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have many more healthy cycles than failure cycles, we also look at precision and recall. In all cases, we assume the model threshold is at $Pr = 0.5$. In order to tune this, we need to look at a test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train/network.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train/network.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, nb_layers, dropout, nb_classes=2):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.nb_layers = nb_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm0 = nn.LSTM(input_size, hidden_size, nb_layers, batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(hidden_size, hidden_size//2, nb_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size//2, nb_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.nb_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.nb_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        h1 = torch.zeros(self.nb_layers, x.size(0), self.hidden_size//2).to(device) \n",
    "        c1 = torch.zeros(self.nb_layers, x.size(0), self.hidden_size//2).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        self.lstm0.flatten_parameters()\n",
    "        out, _ = self.lstm0(x, (h0, c0))\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        self.lstm1.flatten_parameters()\n",
    "        out, _ = self.lstm1(out, (h1, c1))\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        # retrieve hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "       \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train/train.py\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from azureml.core import Run\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import tensorize\n",
    "import network\n",
    "from sklearn.metrics import (recall_score, \n",
    "                             precision_score, \n",
    "                             accuracy_score)\n",
    "\n",
    "\n",
    "def train(run , training_file, \n",
    "          device,input_size, \n",
    "          hidden_size, nb_layers,\n",
    "          dropout, nb_classes):\n",
    "    \n",
    "    X_train, y_train = to_tensors(training_file)\n",
    "    input_size = X_train.shape[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    dataset = utils.TensorDataset(X_train,y_train) \n",
    "    dataloader = utils.DataLoader(dataset)\n",
    "    \n",
    "    network = Network(input_size,hidden_size, nb_layers, dropout, nb_classes).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(nb_epochs):\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            X = X.reshape(-1, sequence_length, input_size).to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = network(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('epoch [{}/{}], loss: {:.4f}'\n",
    "                                   .format(epoch+1,nb_epochs, loss.item()))\n",
    "                run.log('loss', loss.item())      \n",
    "\n",
    "    return network\n",
    "\n",
    "def to_tensors(df_path, istest = False):\n",
    "    '''\n",
    "     Converts dataset to dataset and labels tensors\n",
    "     \n",
    "     params:\n",
    "         df_path: path to csv data file\n",
    "         istest: testing set being passed default to false\n",
    "         \n",
    "     return X (m,50,25), y (m,)\n",
    "    '''\n",
    "    \n",
    "    timestep = 50\n",
    "    \n",
    "    train_df = pd.read_csv(df_path)\n",
    "    X_train, y_train = tensorize(train_df, timestep = timestep, istest = istest)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    return X_train, y_train\n",
    "\n",
    "def evaluate(testfile_path, network, device):\n",
    "    \n",
    "    '''\n",
    "        Evaluate model on testing set\n",
    "        \n",
    "        params:\n",
    "            testfile_path: path to testing file\n",
    "    '''\n",
    "    \n",
    "    X_test,y_test = to_tensors(testfile_path, istest = True)\n",
    "    \n",
    "    X_test = torch.from_numpy(seq_array_test).to(device)\n",
    "    y_test = torch.from_numpy(label_array_test).to(device)\n",
    "    print(X_test.size())\n",
    "\n",
    "    y_pred = network(X_test)\n",
    "    \n",
    "    y_pred_np = y_pred.to('cpu').data.numpy()\n",
    "    y_test_np = y_test.to('cpu').data.numpy()\n",
    "    y_pred_np = np.argmax(y_pred_np, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "    precision_test = precision_score(y_test_np, y_pred_np)\n",
    "    recall_test = recall_score(y_test_np, y_pred_np)\n",
    "    \n",
    "    run.log('Test Accurracy', accuracy)\n",
    "    run.log('Test Precision', precision_test)\n",
    "    run.log('Test Recall', recall_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--nb_epochs', type=int, default=2,\n",
    "                        help='number of epochs to train')\n",
    "    parser.add_argument('--learning_rate', type=float,\n",
    "                        default=1e-3, help='learning rate')\n",
    "    parser.add_argument('--dropout', type=float,\n",
    "                        default=.2, help='drop out')\n",
    "    parser.add_argument('--data_path', type=str, \n",
    "                        help='path to training-set file')\n",
    "    parser.add_argument('--output_dir', type=str, \n",
    "                        help='output directory')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    nb_epochs = args.nb_epochs\n",
    "    learning_rate = args.learning_rate\n",
    "    dropout = args.dropout\n",
    "    data_path = args.data_path\n",
    "    output_dir = args.output_dir\n",
    "   \n",
    "    hidden_size = 128\n",
    "    nb_layers = 1 \n",
    "    nb_classes = 2\n",
    "    batch_size = 32\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok = True)\n",
    "    print('DATA PATH', data_path)\n",
    "    \n",
    "    training_file = os.path.join(data_path, 'preprocessed_train_file.csv')\n",
    "    print('TRAINING FILE', training_file)\n",
    "    X_train, y_train = to_tensors(training_file)\n",
    "    input_size = X_train.shape[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    \n",
    "    dataset = utils.TensorDataset(X_train,y_train) \n",
    "    dataloader = utils.DataLoader(dataset)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    run = Run.get_context()\n",
    "    network = train(run, dataloader, \n",
    "                    device, input_size,\n",
    "                    hidden_size, nb_layers,\n",
    "                    dropout, nb_classes)\n",
    "    evaluate(testfile_path, network, device)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    model_path = os.path.join(output_dir, 'network.pth')\n",
    "    torch.save(network, model_path)\n",
    "    run.register_model(model_name = 'network.pth', model_path = model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "Next, we look at the performance on the test data. Only the last cycle data for each engine id in the test data is kept for testing purposes. In order to compare the results to the template, we pick the last sequence for each id in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--nb_epochs': 2,\n",
    "    '--learning_rate': 1e-3,\n",
    "    '--dropout': .2,\n",
    "    '--data_path': ds_path,\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory = training_dir, \n",
    "                    conda_packages = ['pandas', 'numpy', 'scikit-learn'],\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the model with the test data. We report the model accuracy on the test set, and compare it to the training accuracy. By definition, the training accuracy should be optimistic since the model was optimized for those observations. The test set accuracy is more general, and simulates how the model was intended to be used to predict forward in time. This is the number we should use for reporting how the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the test set confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace=ws, name=exp_name)\n",
    "run = experiment.submit(estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf975ac04a0f48efa4658096ba8272e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix uses absolute counts, so comparing the test and training set confusion matrices is difficult. Instead, it is  better to use precision and recall. \n",
    "\n",
    " * _Precision_ measures how accurate your model predicts failures. What percentage of the failure predictions are actually failures.\n",
    " * _Recall_ measures how well the model captures thos failures. What percentage of the true failures did your model capture.\n",
    " \n",
    "These measures are tightly coupled, and you can typically only choose to maximize one of them (by manipulating the probability threshold) and have to accept the other as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model  \n",
    "\n",
    "The LSTM network is made up of two components, the architecture and the model weights. We'll save these model components in two files, the architecture in a `json` file that the `keras` package can use to rebuild the model, and the weights in an `HDF5` heirachy that rebuild the exact model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/sasuke/dev/amlsamples/deep_predictive_maintenance/lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/amlenv/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Network. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_name = 'lstm.pth'\n",
    "model_path = os.path.join(os.getcwd(), model_name)\n",
    "torch.save(network,model_path)\n",
    "print(\"Model saved to\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the save operations, we can reload the model files into a test model `loaded_model` and rescore the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (dropout): Dropout(p=0.2)\n",
      "  (lstm): LSTM(25, 128, batch_first=True)\n",
      "  (lstm2): LSTM(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "the_model= torch.load(model_path)\n",
    "print(the_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist the model\n",
    "\n",
    "In order to pass the model to our next notebook, we will write the model files to the shared folder within the Azure ML Workbench project. https://docs.microsoft.com/en-us/azure/machine-learning/preview/how-to-read-write-files\n",
    "\n",
    "In the `Code\\3_operationalization.ipynb` Jupyter notebook, we will create the functions needed to operationalize and deploy any model to get realtime predictions. The artifacts created will be stored in one of your Azure storage containers for you to deploy and test your own web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "amlenv",
   "language": "python",
   "name": "amlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
