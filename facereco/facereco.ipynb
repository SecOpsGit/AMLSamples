{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites:\n",
    "\n",
    "Before running this notebook, make sure you have gone through the steps listed below: \n",
    "\n",
    " - You have a workspace created https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started\n",
    " <br>\n",
    " - You have a development environment configured https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AML SDK version : 0.1.74\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from azureml.core import  (Workspace,Run,VERSION, \n",
    "                           Experiment,Datastore)\n",
    "from azureml.core.runconfig import (RunConfiguration,\n",
    "                                    DEFAULT_GPU_IMAGE)\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import BatchAiCompute,ComputeTarget,DsvmCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import (Pipeline, \n",
    "                                   PipelineData)\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.train.widgets import RunDetails\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(\"AML SDK version :\", VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = 'fe375bc2-9f1a-4909-ad0d-9319806d5e97'\n",
    "resource_group = 'amlenv_rg'\n",
    "workspace_name = 'vienna'\n",
    "location = 'westeurope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the config file config.json to: /home/sasuke/dev/amlsamples/facereco/aml_config/config.json\n",
      "Workspace loaded: vienna\n"
     ]
    }
   ],
   "source": [
    "project_folder = os.getcwd()\n",
    "exp_name = \"facereco\"\n",
    "\n",
    "ws = Workspace(workspace_name = workspace_name,\n",
    "               subscription_id = subscription_id,\n",
    "               resource_group = resource_group)\n",
    "\n",
    "ws.write_config()\n",
    "print('Workspace loaded:', ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Store\n",
    "\n",
    "Whilst the preprocessed dataset have been made available, you can download from [here](https://amlgitsamples.blob.core.windows.net/facereco/fgnet.zip), upload it over to your Azure blob storage account and point to it in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = \"amlgitsamples\"\n",
    "container_name = \"facereco\"\n",
    "datastore_name = 'fgnet'\n",
    "datastore = Datastore.register_azure_blob_container(workspace = ws, \n",
    "                                        datastore_name = datastore_name, \n",
    "                                        container_name = container_name,\n",
    "                                        account_name = account_name, \n",
    "                                        overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute target \n",
    "\n",
    "Here we choose to execute the pipeline on Batch AI, but you can easily swap the compute target to other [supported types](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines#key-advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlvm found\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"dlvm\"#\"batchai-cluster\"\n",
    "\n",
    "try:\n",
    "    cluster = ComputeTarget(ws, cluster_name)\n",
    "    print(cluster_name, \"found\")\n",
    "    \n",
    "except ComputeTargetException:\n",
    "    print(cluster_name, \"not found, provisioning....\")\n",
    "    provisioning_config = DsvmCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                    autoscale_enabled = True,\n",
    "                                                                    cluster_min_nodes = 2, \n",
    "                                                                    cluster_max_nodes = 3)\n",
    "\n",
    "    \n",
    "    cluster = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run configuration\n",
    "\n",
    "\n",
    "Here, we define the conda environment along with the packages dependencies needed by our training scripts along with the [run configuration](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#run-configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "cd = CondaDependencies()\n",
    "cd.add_conda_package('pandas')\n",
    "cd.add_channel(channel = 'menpo')\n",
    "cd.add_conda_package('matplotlib')\n",
    "cd.add_conda_package('opencv')\n",
    "cd.add_conda_package('scikit-learn')\n",
    "\n",
    "cd.add_pip_package('keras==2.2.0')\n",
    "cd.add_pip_package('keras-vggface')\n",
    "\n",
    "\n",
    "run_config = RunConfiguration(framework=\"python\",\n",
    "                              conda_dependencies= cd)\n",
    "run_config.target = cluster\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "print(run_config.data_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline data input/output\n",
    "\n",
    "We define a reference to the data store we registered earlier that point to the storage which contains the images.\n",
    "\n",
    "Note that the pipelineData objects uses the default the data store of the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore\n",
      "workspacefilestore\n",
      "fgnet\n",
      "<azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x7f3280651208>\n"
     ]
    }
   ],
   "source": [
    "images_dir = DataReference(data_reference_name = 'images', \n",
    "                             path_on_datastore = 'fgnet', \n",
    "                             mode =\"download\", \n",
    "                             datastore = datastore\n",
    "                          )\n",
    "[print(ds.name) for _,ds in ws.datastores.items()]\n",
    "default_datastore=ws.datastores[\"workspaceblobstore\"]\n",
    "\n",
    "print(default_datastore)\n",
    "\n",
    "metadata_dir = PipelineData(name = 'outputs')\n",
    "vggface_dir = PipelineData(name = 'vggface')\n",
    "pca_dir = PipelineData(name = 'pca')\n",
    "clf_dir = PipelineData(name = 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline steps\n",
    " \n",
    "\n",
    "Below are the four steps files that makes up the pipeline. For detailed description of all steps, refer to the readme file [here](https://github.com/Azure/AMLSamples/blob/master/facereco/readme.md).\n",
    "    \n",
    "   - Step 1 metadata processing [file](./preprocess.py)\n",
    "   - Step 2 VGG-Face features extraction [file](./vggface_features.py)\n",
    "   - Step 3 Dimensionality reduction [file](./pca.py)\n",
    "   - Step 4 Classifier training [file](./classifier.py)\n",
    "   \n",
    "Next, we declare the steps that makes up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata_processing = PythonScriptStep(\n",
    "                            name = 'process images metadata',\n",
    "                            script_name = 'preprocess.py',\n",
    "                            arguments = ['--images_dir', images_dir,\\\n",
    "                                         '--metadata_path', metadata_dir],\n",
    "                            inputs = [images_dir],\n",
    "                            outputs = [metadata_dir],\n",
    "                            target = cluster_name,\n",
    "                            runconfig = run_config\n",
    "                        )\n",
    "\n",
    "\n",
    "vggface_features = PythonScriptStep(\n",
    "                            name = 'VGG-face features extractor',\n",
    "                            script_name = 'vggface_features.py',\n",
    "                            arguments = ['--metadata_path', metadata_dir,\\\n",
    "                                         '--images_dir', images_dir,\\\n",
    "                                        '--vggface_path', vggface_dir],\n",
    "                            inputs = [metadata_dir, images_dir],\n",
    "                            outputs = [vggface_dir],\n",
    "                            target = cluster_name,\n",
    "                            runconfig = run_config\n",
    "                        )\n",
    "\n",
    "pca_features = PythonScriptStep(\n",
    "                            name = 'PCA features extractor',\n",
    "                            script_name = 'pca.py',\n",
    "                            arguments = ['--vggface_path', vggface_dir,\\\n",
    "                                        '--pca_path', pca_dir],\n",
    "                            inputs = [vggface_dir],\n",
    "                            outputs = [pca_dir],\n",
    "                            target = cluster_name,\n",
    "                            runconfig = run_config\n",
    "                        )\n",
    "\n",
    "classifier_step = PythonScriptStep(\n",
    "                            name = 'Fit classifier',\n",
    "                            script_name = 'classifier.py',\n",
    "                            arguments = ['--vggface_path', vggface_dir,\\\n",
    "                                        '--pca_path', pca_dir,\\\n",
    "                                        '--clf_path', clf_dir],\n",
    "                            inputs = [vggface_dir, pca_dir],\n",
    "                            outputs = [clf_dir],\n",
    "                            target = cluster_name,\n",
    "                            runconfig = run_config\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline execution\n",
    "\n",
    "Finally we put it all together, construct an experiment and train the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created underlying module 1020705a-1d63-4687-b867-6610b93fd3df for StepId [aafe4ec8] - Fit classifier. (This will generate a new run.)\n",
      "Created underlying module b5e8c7a4-2363-4b85-bb7a-e5a2f2858282 for StepId [30b349a8] - VGG-face features extractor. (This will generate a new run.)\n",
      "Created underlying module 101fedea-0e60-4ac0-a89d-f8acda09c51c for StepId [13ea2319] - process images metadata. (This will generate a new run.)\n",
      "Created underlying module fd41703b-7efc-464e-9dc0-f2b4462bc22f for StepId [d1a33a82] - PCA features extractor. (This will generate a new run.)\n",
      "Created datasource id 841b7a4c-c8e1-4c73-a4af-38c608af12d0 for StepId [61a2497f] - images. (Consumers of this data will generate new runs.)\n",
      "Created datasource id f3c66d99-488b-4280-86fe-42cde320fa02 for StepId [ebec7b64] - images. (Consumers of this data will generate new runs.)\n",
      "Submitted pipeline run: 9cc75ade-9ea4-4b19-a27f-2beec8d0868f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a6a3ceaf8d4f49a7de3bd706c06fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5268138b6e4047aee5e2777b507ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'display': ''})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline(default_datastore=ws.datastores[\"workspaceblobstore\"],\n",
    "                description = 'face recognition pipeline', \n",
    "                default_source_directory = project_folder,\n",
    "                workspace = ws,\n",
    "                steps = [classifier_step]\n",
    "                   )\n",
    "\n",
    "pipeline_run = Experiment(workspace=ws, name =\"Face_recognition_exp\").submit(pipeline, regenerate_outputs=True)\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec log: [2018-11-23 14:58:42Z] The job is initialized and Will be submitted to target MLC\n",
      "[2018-11-23 14:58:43Z] Start Run in Execution Service\n",
      "[2018-11-23 14:58:45Z] Failed to start the job because of error: Microsoft.RelInfra.Extensions.HttpRequestDetailException: Response status code does not indicate success: 400 (Your runconfig has DataStoreMountConfiguration. However mounting is not supported on this type(Remot).\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"Your runconfig has DataStoreMountConfiguration. However mounting is not supported on this type(Remote) of compute dlvm. Please remove from run config and retry again.\",\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": {\n",
      "      \"type\": \"Microsoft.MachineLearning.Common.WebApi.Exceptions.BadRequestException\",\n",
      "      \"message\": \"Your runconfig has DataStoreMountConfiguration. However mounting is not supported on this type(Remote) of compute dlvm. Please remove from run config and retry again.\",\n",
      "      \"stackTrace\": \"   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.CheckMountSupported(ComputeTargetType targetType, RunConfiguration runConfig) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 796\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.StartRun(ConfigurationManager configurationManager, Guid subscriptionId, String resourceGroupName, String workspaceName, String experimentName, RunDefinition definition, Stream zipStream, RunId runId) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 536\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.StartSnapshotRun(Guid subscriptionId, String resourceGroupName, String workspaceName, String experimentName, RunDefinition definition, RunId runId) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 218\\n   at lambda_method(Closure , Object )\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\n",
      "      \"innerException\": null,\n",
      "      \"data\": {},\n",
      "      \"errorResponse\": null\n",
      "    }\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": \"42c8504219ef7d4b8ce9c6863eb00a98\",\n",
      "    \"request\": \"rP6oq/NNiW8=\"\n",
      "  }\n",
      "}\n",
      "   at Microsoft.RelInfra.Extensions.HttpClientExtensions.EnsureSuccessStatusCodeAsync(HttpResponseMessage response, Boolean ensureStrictSuccess) in d:\\dbs\\sh\\Ae\\1022_174345\\cmd\\5\\src\\RelInfra\\RelInfra.Common.Library\\src\\Extensions\\HttpClientExtensions.cs:line 611\n",
      "   at Microsoft.RelInfra.Extensions.HttpClientExtensions.PostJsonAsync[TRet](HttpClient client, String serverPath, String json, Boolean ensureStrictSuccess, IDictionary`2 customHeaders) in d:\\dbs\\sh\\Ae\\1022_174345\\cmd\\5\\src\\RelInfra\\RelInfra.Common.Library\\src\\Extensions\\HttpClientExtensions.cs:line 154\n",
      "   at Microsoft.Aether.EsCloud.Common.Client.ExecutionServiceClient.StartSnapshotRunAsync(RunDefinition runDefinition, String runId) in d:\\dbs\\sh\\Ae\\1030_211647_0\\cmd\\51\\src\\aether\\platform\\backendV2\\Clouds\\ESCloud\\ESCloudCommon\\Client\\ExecutionServiceClient.cs:line 64\n",
      "   at Microsoft.Aether.EsCloud.Common.JobProcessor.StartRunAsync(EsCloudJobMetadata job) in d:\\dbs\\sh\\Ae\\1030_211647_0\\cmd\\51\\src\\aether\\platform\\backendV2\\Clouds\\ESCloud\\ESCloudCommon\\JobProcessor.cs:line 164\n",
      "\n",
      "stdout log: \n",
      "stderr log: \n",
      "Job log written to logs-process images metadata.txt\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import StepRun\n",
    "\n",
    "step_run = StepRun(experiment = ws.experiments[\"Face_recognition_exp\"],\\\n",
    "                   pipeline_run_id = \"9cc75ade-9ea4-4b19-a27f-2beec8d0868f\",\\\n",
    "                   node_id = \"13ea2319\",\n",
    "                   step_run_id = \"9cc75ade9ea44b19a27f2beec8d0868f_13ea2319_11-23-2018_02-58-38_PM\")\n",
    "\n",
    "joblog = step_run.get_job_log()\n",
    "print('exec log:', joblog)\n",
    "\n",
    "stdout_log = step_run.get_stdout_log()\n",
    "print('stdout log:', stdout_log)\n",
    "\n",
    "stderr_log = step_run.get_stderr_log()\n",
    "print('stderr log:', stderr_log)\n",
    "\n",
    "with open(project_folder + \"\\\\logs-\" + step_run.name + \".txt\", \"w\") as f:\n",
    "    f.write(joblog)\n",
    "    print(\"Job log written to logs-\"+ step_run.name + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amlenv]",
   "language": "python",
   "name": "conda-env-amlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
